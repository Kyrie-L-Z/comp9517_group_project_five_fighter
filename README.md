# ðŸ›°ï¸ COMP9517 Group Project â€“ Remote Sensing Image Classification System

This project implements **two** approaches for remoteâ€‘sensing image classification:

1. ðŸ” **Traditional Machineâ€‘Learning (ML) pipeline**  
   *SIFT / LBP* â€¯+â€¯ *Bag of Visual Words (BoW)* â€¯+â€¯ *Color Histograms* â€¯+â€¯ **4 classifiers**

2. ðŸ¤– **Deepâ€‘Learning (DL) pipeline**  
   *ResNet18 / MobileNetV2* â€¯+â€¯ *Data Augmentation* â€¯+â€¯ *Imbalancedâ€‘data training* â€¯+â€¯ *Occlusionâ€‘robustness testing*

---

## ðŸ“ Project Structure

```text
comp9517_group_project/
â”‚
â”œâ”€â”€ Aerial_Landscapes/               # Dataset (already organised by class)
â”‚
â”œâ”€â”€ DL_method/                       # Deepâ€‘learning implementation
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ dataset_manager.py       # Dataset loading & splitting (supports imbalance simulation)
â”‚   â”‚   â”œâ”€â”€ model_builder.py         # Build ResNet18 / MobileNetV2 models
â”‚   â”‚   â”œâ”€â”€ train_utils.py           # Training & evaluation helpers
â”‚   â”‚   â”œâ”€â”€ gradcam_utils.py         # Gradâ€‘CAM visualisation
â”‚   â”‚   â”œâ”€â”€ occlusion_utils.py       # Occlusion testing (robustness analysis)
â”‚   â”œâ”€â”€ run_dl_experiment_main.py    # Entry script â€“ run all DL experiments
â”‚   â””â”€â”€ demo_dl_method.ipynb         # Notebook showing the full DL workflow
â”‚
â”œâ”€â”€ ML_method/                       # Traditional ML implementation
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ data_manager.py          # Sample image paths and train/val/test split
â”‚   â”‚   â”œâ”€â”€ sift_processor.py        # Extract SIFT descriptors
â”‚   â”‚   â”œâ”€â”€ lbp_processor.py         # Extract LBP descriptors
â”‚   â”‚   â”œâ”€â”€ bow_encoder.py           # Build BoW vocabulary & extract BoW features
â”‚   â”‚   â”œâ”€â”€ feature_fusion.py        # Extract + fuse colourâ€‘histogram features
â”‚   â”‚   â”œâ”€â”€ evaluator.py             # Output evaluation metrics
â”‚   â”œâ”€â”€ demo_ml_method.py            # Entry script â€“ run all classifier combos
â”‚   â””â”€â”€ run_ml_experiment_main.py    # Notebook showing the full ML workflow
â”‚
â”œâ”€â”€ README.md                        # Project documentation (bilingual CN/EN)
â””â”€â”€ *.md                             # Supplementary method/model notes
```

---

## âœ… Key Features

- **SIFT** and **LBP** feature extraction with sideâ€‘byâ€‘side comparison  
- **BoW model** + **colourâ€‘histogram fusion**  
- Integration of **four classifiers** â€“Â SVM, Randomâ€¯Forest, XGBoost, KNN  
- Training & testing with **ResNet18** and **MobileNetV2** architectures  
- **Imbalancedâ€‘dataset simulation** (uneven image counts per class)  
- **Occlusion / noise** robustness testing  
- Automatic export of **comprehensive comparison tables** (Accuracy, F1, training time, â€¦)

---

## ðŸ“Š SIFT vsâ€¯LBP + 4Â Classifiers & Dataâ€‘Augmentation Comparison (complete metrics)

### ðŸ“‹ BoWâ€‘only

| Feature    | Model         | Accuracy |   F1   | Precision | Recall | Testâ€¯Timeâ€¯(s) | Setting |
|:----------:|:-------------:|:-------:|:------:|:---------:|:------:|:-------------:|:-------:|
| SIFT_plain | SVM_RBF       | 69.42â€¯% | 0.691 | 0.694 | 0.694 | 1.171 | BoW |
| SIFT_plain | RandomForest  | 63.08â€¯% | 0.618 | 0.621 | 0.631 | 0.035 | BoW |
| SIFT_plain | XGBoost       | 66.92â€¯% | 0.670 | 0.673 | 0.669 | 0.014 | BoW |
| SIFT_plain | KNN           | 55.42â€¯% | 0.539 | 0.589 | 0.554 | 0.060 | BoW |
| LBP_plain  | SVM_RBF       | 41.42â€¯% | 0.411 | 0.420 | 0.414 | 0.763 | BoW |
| LBP_plain  | RandomForest  | 40.83â€¯% | 0.402 | 0.407 | 0.408 | 0.065 | BoW |
| LBP_plain  | XGBoost       | 40.25â€¯% | 0.401 | 0.419 | 0.403 | 0.009 | BoW |
| LBP_plain  | KNN           | 24.83â€¯% | 0.206 | 0.274 | 0.248 | 0.049 | BoW |

### ðŸ“‹ With Colourâ€‘Histogram Fusion + Augmentation

| Feature   | Model        | Accuracy |   F1   | Precision | Recall | Testâ€¯Timeâ€¯(s) | Setting |
|:---------:|:------------:|:--------:|:------:|:---------:|:------:|:-------------:|:-------:|
| SIFT_full | SVM_RBF      | 73.83â€¯% | 0.737 | 0.742 | 0.738 | 2.629 | +ColourHistâ€¯+Aug |
| SIFT_full | RandomForest | 71.08â€¯% | 0.704 | 0.716 | 0.711 | 0.040 | +ColourHistâ€¯+Aug |
| SIFT_full | XGBoost      | 76.50â€¯% | 0.766 | 0.774 | 0.765 | 0.019 | +ColourHistâ€¯+Aug |
| SIFT_full | KNN          | 56.67â€¯% | 0.555 | 0.576 | 0.567 | 0.157 | +ColourHistâ€¯+Aug |
| LBP_full  | SVM_RBF      | 58.25â€¯% | 0.575 | 0.579 | 0.583 | 2.938 | +ColourHistâ€¯+Aug |
| LBP_full  | RandomForest | 67.50â€¯% | 0.669 | 0.673 | 0.675 | 0.044 | +ColourHistâ€¯+Aug |
| LBP_full  | XGBoost      | 70.83â€¯% | 0.708 | 0.711 | 0.708 | 0.013 | +ColourHistâ€¯+Aug |
| LBP_full  | KNN          | 44.58â€¯% | 0.433 | 0.454 | 0.446 | 0.127 | +ColourHistâ€¯+Aug |

---

## ðŸ“Š Deepâ€‘Learning Results (ResNet18 vsâ€¯MobileNetV2)

### Balanced Dataset â€“â€¯plain vsâ€¯augmented

| Model       | Setting          | Accuracy |   F1   | Precision | Recall | Trainâ€¯Timeâ€¯(s) |
|-------------|------------------|:--------:|:------:|:---------:|:------:|:--------------:|
| ResNet18    | Balanced         | 0.9817 | 0.9816 | 0.9818 | 0.9817 | 2128.19 |
| ResNet18    | Balancedâ€¯+â€¯Aug   | 0.9779 | 0.9779 | 0.9781 | 0.9779 | 1788.94 |
| MobileNetV2 | Balanced         | 0.9754 | 0.9754 | 0.9756 | 0.9754 | 2042.97 |
| MobileNetV2 | Balancedâ€¯+â€¯Aug   | 0.9800 | 0.9800 | 0.9800 | 0.9800 | 1210.77 |

### Imbalanced Dataset â€“â€¯plain vsâ€¯augmented

| Model       | Setting            | Accuracy |   F1   | Precision | Recall | Trainâ€¯Timeâ€¯(s) |
|-------------|--------------------|:--------:|:------:|:---------:|:------:|:--------------:|
| ResNet18    | Imbalanced         | 0.9593 | 0.9592 | 0.9598 | 0.9593 | 512.33 |
| ResNet18    | Imbalancedâ€¯+â€¯Aug   | 0.9536 | 0.9536 | 0.9553 | 0.9536 | 508.44 |
| MobileNetV2 | Imbalanced         | 0.9593 | 0.9593 | 0.9601 | 0.9593 | 505.32 |
| MobileNetV2 | Imbalancedâ€¯+â€¯Aug   | 0.9688 | 0.9687 | 0.9697 | 0.9688 | 506.82 |

#### Performance on augmented classes only

| Model       | Class        | Setting            |   F1   | Precision | Recall |
|-------------|--------------|--------------------|:------:|:---------:|:------:|
| ResNet18    | Residential  | Imbalanced         | 0.8750 | 0.8750 | 0.8750 |
| ResNet18    | River        | Imbalanced         | 0.7000 | 0.7778 | 0.6364 |
| ResNet18    | Residential  | Imbalancedâ€¯+â€¯Aug   | 0.7778 | 0.7000 | 0.8750 |
| ResNet18    | River        | Imbalancedâ€¯+â€¯Aug   | 0.8571 | 0.9000 | 0.8182 |
| MobileNetV2 | Residential  | Imbalanced         | 0.8235 | 0.7778 | 0.8750 |
| MobileNetV2 | River        | Imbalanced         | 0.8000 | 0.8889 | 0.7273 |
| MobileNetV2 | Residential  | Imbalancedâ€¯+â€¯Aug   | 0.8000 | 0.8571 | 0.7500 |
| MobileNetV2 | River        | Imbalancedâ€¯+â€¯Aug   | 0.9524 | 1.0000 | 0.9091 |

### ðŸ§ª Robustness under Occlusion

| Scenario                     | Model          | Accuracy |   F1   | Precision | Recall |
|------------------------------|----------------|:--------:|:------:|:---------:|:------:|
| OcclusionTest_ResNet_Plain   | resnet_plain   | 92.67â€¯% | 0.930 | 0.953 | 0.927 |
| OcclusionTest_Mobile_Plain   | mobilenet_plain| 77.38â€¯% | 0.808 | 0.942 | 0.774 |
| OcclusionTest_ResNet_Aug     | resnet_aug     | 89.60â€¯% | 0.870 | 0.939 | 0.850 |
| OcclusionTest_Mobile_Aug     | mobilenet_aug  | 86.25â€¯% | 0.878 | 0.944 | 0.863 |

---

## ðŸ§ª How to Run

### â–¶ Traditional ML pipeline
```bash
cd ML_method
python run_ml_experiment_main.py
```

### â–¶ Deepâ€‘learning pipeline
```bash
cd DL_method
python run_dl_experiment_main.py
```

Or open the corresponding Jupyter notebooks for interactive execution and visualisation.

---

## ðŸ‘¥ Authors

*Zhiâ€¯Li & GroupÂ FiveÂ Fighters* Â· COMP9517Â T1Â 2025

---

## ðŸ§  Models & Versions

### ðŸ“Œ Deepâ€‘learning models
- **ResNet18** â€“ `torchvision.models.resnet18` (preâ€‘trained)  
- **MobileNetV2** â€“ `torchvision.models.mobilenet_v2` (preâ€‘trained)  

> Frameworks  
> â€¢ **PyTorch** â‰¥Â 1.13  
> â€¢ **torchvision** â‰¥Â 0.14  
> â€¢ **pytorchâ€‘grad-cam** â‰¥Â 1.3.8  

### ðŸ§ª Traditional ML models
- **SVM_RBF** â€“ `sklearn.svm.SVC`  
- **RandomForest** â€“ `sklearn.ensemble.RandomForestClassifier`  
- **XGBoost** â€“ `xgboost.XGBClassifier`  
- **KNN** â€“ `sklearn.neighbors.KNeighborsClassifier`

### ðŸ”§ Main dependencies
`numpy`, `pandas`, `matplotlib`, `seaborn`, `opencv-python`, `scikit-image`,  
`scikitâ€‘learn`Â â‰¥â€¯1.1, `xgboost`Â â‰¥â€¯1.7, `pytorchâ€‘grad-cam`

---

## ðŸ’¡ Future Improvements

- Add more CNN backbones (e.g., EfficientNet, ConvNeXt)  
- Visualise training curves (loss / accuracy)  
- Checkpoint saving & loading  
- Integrate adversarial attack/defence modules  
- Extend to further remoteâ€‘sensing tasks (segmentation, detection)
